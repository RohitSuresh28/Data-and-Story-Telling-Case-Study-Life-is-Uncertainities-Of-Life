{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51df90c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DATA PREPROCESSING ANALYSIS REPORT\n",
      "================================================================================\n",
      "\n",
      "1. LOADING DATASET...\n",
      "   Original dataset shape: (542650, 7)\n",
      "   Columns: ['person_id', 'matched_label', 'matched_description', 'matched_code', 'start_date', 'end_date', 'university_studies']\n",
      "   Total records: 542,650\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load the dataset\n",
    "print(\"=\" * 80)\n",
    "print(\"DATA PREPROCESSING ANALYSIS REPORT\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\n1. LOADING DATASET...\")\n",
    "df = pd.read_csv('filter-jobs-requiring-studies.csv')\n",
    "print(f\"   Original dataset shape: {df.shape}\")\n",
    "print(f\"   Columns: {list(df.columns)}\")\n",
    "print(f\"   Total records: {len(df):,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46a4afd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. INITIAL DATA ANALYSIS\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "2.1 Data Types:\n",
      "person_id               int64\n",
      "matched_label          object\n",
      "matched_description    object\n",
      "matched_code           object\n",
      "start_date             object\n",
      "end_date               object\n",
      "university_studies       bool\n",
      "dtype: object\n",
      "\n",
      "2.2 Null Values Count:\n",
      "matched_code      5097\n",
      "start_date       52740\n",
      "end_date        121141\n",
      "dtype: int64\n",
      "\n",
      "2.3 Empty Strings Count:\n",
      "No empty strings found\n",
      "\n",
      "2.4 'Unknown' Values Count (case-insensitive):\n",
      "{'matched_label': 87313, 'matched_description': 87313, 'matched_code': 87313, 'start_date': 52740, 'end_date': 121141}\n",
      "\n",
      "2.5 Sample Rows with Issues:\n",
      "   Found 206,203 rows with issues\n",
      "    person_id matched_label  \\\n",
      "13          1       unknown   \n",
      "16          2    accountant   \n",
      "24          9       unknown   \n",
      "33         14       unknown   \n",
      "34         14       unknown   \n",
      "35         14       unknown   \n",
      "36         14       unknown   \n",
      "37         14       unknown   \n",
      "48         21       unknown   \n",
      "56         26       unknown   \n",
      "\n",
      "                                  matched_description matched_code start_date  \\\n",
      "13                                            unknown      unknown    Q2 2003   \n",
      "16  Accountants review and analyse financial state...       2411.1        NaN   \n",
      "24                                            unknown      unknown    Q2 2013   \n",
      "33                                            unknown      unknown    Q3 2010   \n",
      "34                                            unknown          NaN    Q1 2009   \n",
      "35                                            unknown          NaN    Q1 2008   \n",
      "36                                            unknown          NaN    Q1 2007   \n",
      "37                                            unknown          NaN    Q1 2005   \n",
      "48                                            unknown          NaN    Q1 2015   \n",
      "56                                            unknown      unknown    Q4 2011   \n",
      "\n",
      "   end_date  university_studies  \n",
      "13  Q4 2005                True  \n",
      "16      NaN                True  \n",
      "24  Q3 2013                True  \n",
      "33  Q4 2011                True  \n",
      "34      NaN                True  \n",
      "35      NaN                True  \n",
      "36      NaN                True  \n",
      "37  Q4 2006                True  \n",
      "48      NaN                True  \n",
      "56  Q2 2013                True  \n"
     ]
    }
   ],
   "source": [
    "# Initial Data Analysis\n",
    "print(\"\\n2. INITIAL DATA ANALYSIS\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Check data types\n",
    "print(\"\\n2.1 Data Types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Check for null values\n",
    "print(\"\\n2.2 Null Values Count:\")\n",
    "null_counts = df.isnull().sum()\n",
    "print(null_counts[null_counts > 0] if null_counts.sum() > 0 else \"No null values found\")\n",
    "\n",
    "# Check for empty strings\n",
    "print(\"\\n2.3 Empty Strings Count:\")\n",
    "empty_strings = {}\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':\n",
    "        empty_count = (df[col] == '').sum()\n",
    "        if empty_count > 0:\n",
    "            empty_strings[col] = empty_count\n",
    "print(empty_strings if empty_strings else \"No empty strings found\")\n",
    "\n",
    "# Check for 'unknown' values (case-insensitive)\n",
    "print(\"\\n2.4 'Unknown' Values Count (case-insensitive):\")\n",
    "unknown_counts = {}\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':\n",
    "        unknown_count = df[col].astype(str).str.lower().str.strip().isin(['unknown', 'nan', 'none']).sum()\n",
    "        if unknown_count > 0:\n",
    "            unknown_counts[col] = unknown_count\n",
    "print(unknown_counts if unknown_counts else \"No 'unknown' values found\")\n",
    "\n",
    "# Display sample of problematic rows\n",
    "print(\"\\n2.5 Sample Rows with Issues:\")\n",
    "issues_mask = (\n",
    "    df.isnull().any(axis=1) | \n",
    "    (df.select_dtypes(include=['object']).astype(str).apply(lambda x: x.str.lower().str.strip().isin(['unknown', 'nan', 'none'])).any(axis=1)) |\n",
    "    (df.select_dtypes(include=['object']).astype(str).apply(lambda x: x == '').any(axis=1))\n",
    ")\n",
    "if issues_mask.sum() > 0:\n",
    "    print(f\"   Found {issues_mask.sum():,} rows with issues\")\n",
    "    print(df[issues_mask].head(10))\n",
    "else:\n",
    "    print(\"   No issues found in sample\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e7242e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. CHECKING FOR INCONSISTENCIES\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "3.1 Date Format Analysis:\n",
      "   start_date: 0 invalid format entries\n",
      "   end_date: 0 invalid format entries\n",
      "\n",
      "3.2 Date Logic Validation:\n",
      "   Found 12 rows where end_date is before start_date\n",
      "   Sample invalid date ranges:\n",
      "        person_id start_date end_date\n",
      "14122       11599    Q1 2011  Q4 2010\n",
      "93960       77134    Q1 2016  Q4 2015\n",
      "127009     103824    Q1 2008  Q4 2007\n",
      "260040     213714    Q1 2014  Q4 2012\n",
      "276401     227068    Q1 2007  Q4 1993\n",
      "\n",
      "3.3 Duplicate Rows:\n",
      "   Found 13,528 duplicate rows\n",
      "\n",
      "3.4 Matched Code Validation:\n",
      "   Found 83,242 entries with unexpected code format\n",
      "   Sample invalid codes: ['unknown', '1324.3.1.6.10', '1221.3.2.1.1', '1324.3.1.6.7', '1221.3.2.1.4']\n"
     ]
    }
   ],
   "source": [
    "# Check for inconsistencies in date columns\n",
    "print(\"\\n3. CHECKING FOR INCONSISTENCIES\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Date format validation\n",
    "print(\"\\n3.1 Date Format Analysis:\")\n",
    "date_columns = ['start_date', 'end_date']\n",
    "\n",
    "for col in date_columns:\n",
    "    if col in df.columns:\n",
    "        # Check for valid date format (Q1 YYYY, Q2 YYYY, etc.)\n",
    "        valid_format = df[col].astype(str).str.match(r'^Q[1-4]\\s+\\d{4}$', na=False)\n",
    "        invalid_count = (~valid_format & df[col].notna()).sum()\n",
    "        print(f\"   {col}: {invalid_count:,} invalid format entries\")\n",
    "        if invalid_count > 0:\n",
    "            invalid_samples = df[~valid_format & df[col].notna()][col].unique()[:5]\n",
    "            print(f\"      Sample invalid formats: {list(invalid_samples)}\")\n",
    "\n",
    "# Check for logical inconsistencies (end_date before start_date)\n",
    "print(\"\\n3.2 Date Logic Validation:\")\n",
    "if 'start_date' in df.columns and 'end_date' in df.columns:\n",
    "    # Convert dates to comparable format\n",
    "    def parse_quarter(date_str):\n",
    "        if pd.isna(date_str) or str(date_str).strip() == '':\n",
    "            return None\n",
    "        try:\n",
    "            parts = str(date_str).strip().split()\n",
    "            if len(parts) == 2 and parts[0].startswith('Q'):\n",
    "                quarter = int(parts[0][1])\n",
    "                year = int(parts[1])\n",
    "                return year * 4 + quarter\n",
    "            return None\n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "    df['start_quarter_num'] = df['start_date'].apply(parse_quarter)\n",
    "    df['end_quarter_num'] = df['end_date'].apply(parse_quarter)\n",
    "    \n",
    "    # Check for invalid date ranges\n",
    "    invalid_ranges = (\n",
    "        (df['start_quarter_num'].notna() & df['end_quarter_num'].notna()) &\n",
    "        (df['end_quarter_num'] < df['start_quarter_num'])\n",
    "    )\n",
    "    print(f\"   Found {invalid_ranges.sum():,} rows where end_date is before start_date\")\n",
    "    if invalid_ranges.sum() > 0:\n",
    "        print(f\"   Sample invalid date ranges:\")\n",
    "        print(df[invalid_ranges][['person_id', 'start_date', 'end_date']].head(5))\n",
    "\n",
    "# Check for duplicate rows\n",
    "print(\"\\n3.3 Duplicate Rows:\")\n",
    "duplicate_count = df.duplicated().sum()\n",
    "print(f\"   Found {duplicate_count:,} duplicate rows\")\n",
    "\n",
    "# Check for inconsistent data types in matched_code\n",
    "print(\"\\n3.4 Matched Code Validation:\")\n",
    "if 'matched_code' in df.columns:\n",
    "    # Check if codes follow expected pattern (numbers with dots)\n",
    "    code_pattern = df['matched_code'].astype(str).str.match(r'^\\d+\\.?\\d*\\.?\\d*\\.?\\d*$', na=False)\n",
    "    invalid_codes = (~code_pattern & df['matched_code'].notna() & (df['matched_code'].astype(str).str.strip() != '')).sum()\n",
    "    print(f\"   Found {invalid_codes:,} entries with unexpected code format\")\n",
    "    if invalid_codes > 0:\n",
    "        invalid_samples = df[~code_pattern & df['matched_code'].notna() & (df['matched_code'].astype(str).str.strip() != '')]['matched_code'].unique()[:5]\n",
    "        print(f\"   Sample invalid codes: {list(invalid_samples)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9616bcf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4. CLEANING THE DATA\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "4.1 Removing rows with 'unknown' values...\n",
      "   Removed 87,313 rows with 'unknown' values\n",
      "\n",
      "4.2 Removing rows with null values...\n",
      "   Removed 118,890 rows with null values\n",
      "\n",
      "4.3 Removing rows with empty strings...\n",
      "   Removed 0 rows with empty strings\n",
      "\n",
      "4.4 Removing rows with invalid date formats...\n",
      "   Removed 0 rows with invalid date formats\n",
      "\n",
      "4.5 Removing rows with invalid date ranges...\n",
      "   Removed 5 rows with invalid date ranges\n",
      "\n",
      "4.6 Removing duplicate rows...\n",
      "   Removed 3,058 duplicate rows\n",
      "\n",
      "   Total rows removed: 209,266\n",
      "   Final dataset shape: (333384, 7)\n",
      "   Data retention: 61.44%\n"
     ]
    }
   ],
   "source": [
    "# CLEANING THE DATA\n",
    "print(\"\\n4. CLEANING THE DATA\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Create a copy for cleaning\n",
    "df_clean = df.copy()\n",
    "initial_rows = len(df_clean)\n",
    "\n",
    "# Step 1: Remove rows with 'unknown' values (case-insensitive)\n",
    "print(\"\\n4.1 Removing rows with 'unknown' values...\")\n",
    "before_unknown = len(df_clean)\n",
    "unknown_mask = (\n",
    "    df_clean['matched_label'].astype(str).str.lower().str.strip().isin(['unknown', 'nan', 'none']) |\n",
    "    df_clean['matched_description'].astype(str).str.lower().str.strip().isin(['unknown', 'nan', 'none']) |\n",
    "    df_clean['matched_code'].astype(str).str.lower().str.strip().isin(['unknown', 'nan', 'none'])\n",
    ")\n",
    "df_clean = df_clean[~unknown_mask]\n",
    "removed_unknown = before_unknown - len(df_clean)\n",
    "print(f\"   Removed {removed_unknown:,} rows with 'unknown' values\")\n",
    "\n",
    "# Step 2: Remove null values\n",
    "print(\"\\n4.2 Removing rows with null values...\")\n",
    "before_null = len(df_clean)\n",
    "df_clean = df_clean.dropna()\n",
    "removed_null = before_null - len(df_clean)\n",
    "print(f\"   Removed {removed_null:,} rows with null values\")\n",
    "\n",
    "# Step 3: Remove empty strings\n",
    "print(\"\\n4.3 Removing rows with empty strings...\")\n",
    "before_empty = len(df_clean)\n",
    "for col in df_clean.columns:\n",
    "    if df_clean[col].dtype == 'object':\n",
    "        df_clean = df_clean[df_clean[col].astype(str).str.strip() != '']\n",
    "removed_empty = before_empty - len(df_clean)\n",
    "print(f\"   Removed {removed_empty:,} rows with empty strings\")\n",
    "\n",
    "# Step 4: Remove rows with invalid date formats\n",
    "print(\"\\n4.4 Removing rows with invalid date formats...\")\n",
    "before_date = len(df_clean)\n",
    "date_pattern = r'^Q[1-4]\\s+\\d{4}$'\n",
    "valid_start = df_clean['start_date'].astype(str).str.match(date_pattern, na=False)\n",
    "valid_end = df_clean['end_date'].astype(str).str.match(date_pattern, na=False)\n",
    "df_clean = df_clean[valid_start & valid_end]\n",
    "removed_date = before_date - len(df_clean)\n",
    "print(f\"   Removed {removed_date:,} rows with invalid date formats\")\n",
    "\n",
    "# Step 5: Remove rows with invalid date ranges (end_date before start_date)\n",
    "print(\"\\n4.5 Removing rows with invalid date ranges...\")\n",
    "before_range = len(df_clean)\n",
    "\n",
    "# Define helper function to parse quarter dates\n",
    "def parse_quarter(date_str):\n",
    "    if pd.isna(date_str) or str(date_str).strip() == '':\n",
    "        return None\n",
    "    try:\n",
    "        parts = str(date_str).strip().split()\n",
    "        if len(parts) == 2 and parts[0].startswith('Q'):\n",
    "            quarter = int(parts[0][1])\n",
    "            year = int(parts[1])\n",
    "            return year * 4 + quarter\n",
    "        return None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "df_clean['start_quarter_num'] = df_clean['start_date'].apply(parse_quarter)\n",
    "df_clean['end_quarter_num'] = df_clean['end_date'].apply(parse_quarter)\n",
    "invalid_ranges = (\n",
    "    (df_clean['start_quarter_num'].notna() & df_clean['end_quarter_num'].notna()) &\n",
    "    (df_clean['end_quarter_num'] < df_clean['start_quarter_num'])\n",
    ")\n",
    "df_clean = df_clean[~invalid_ranges]\n",
    "removed_range = before_range - len(df_clean)\n",
    "print(f\"   Removed {removed_range:,} rows with invalid date ranges\")\n",
    "\n",
    "# Step 6: Remove duplicate rows\n",
    "print(\"\\n4.6 Removing duplicate rows...\")\n",
    "before_dup = len(df_clean)\n",
    "df_clean = df_clean.drop_duplicates()\n",
    "removed_dup = before_dup - len(df_clean)\n",
    "print(f\"   Removed {removed_dup:,} duplicate rows\")\n",
    "\n",
    "# Clean up temporary columns\n",
    "df_clean = df_clean.drop(columns=['start_quarter_num', 'end_quarter_num'], errors='ignore')\n",
    "\n",
    "final_rows = len(df_clean)\n",
    "total_removed = initial_rows - final_rows\n",
    "\n",
    "print(f\"\\n   Total rows removed: {total_removed:,}\")\n",
    "print(f\"   Final dataset shape: {df_clean.shape}\")\n",
    "print(f\"   Data retention: {(final_rows/initial_rows*100):.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d720efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5. FINAL DATA QUALITY REPORT\n",
      "================================================================================\n",
      "\n",
      "Dataset Statistics:\n",
      "   Original rows: 542,650\n",
      "   Cleaned rows: 333,384\n",
      "   Rows removed: 209,266 (38.56%)\n",
      "\n",
      "Column-wise Summary:\n",
      "   person_id:\n",
      "      - Null values: 0\n",
      "      - Data type: int64\n",
      "   matched_label:\n",
      "      - Null values: 0\n",
      "      - Empty strings: 0\n",
      "      - Unknown values: 0\n",
      "      - Unique values: 2,799\n",
      "   matched_description:\n",
      "      - Null values: 0\n",
      "      - Empty strings: 0\n",
      "      - Unknown values: 0\n",
      "      - Unique values: 2,799\n",
      "   matched_code:\n",
      "      - Null values: 0\n",
      "      - Empty strings: 0\n",
      "      - Unknown values: 0\n",
      "      - Unique values: 2,799\n",
      "   start_date:\n",
      "      - Null values: 0\n",
      "      - Empty strings: 0\n",
      "      - Unknown values: 0\n",
      "      - Unique values: 205\n",
      "   end_date:\n",
      "      - Null values: 0\n",
      "      - Empty strings: 0\n",
      "      - Unknown values: 0\n",
      "      - Unique values: 196\n",
      "   university_studies:\n",
      "      - Null values: 0\n",
      "      - Data type: bool\n",
      "\n",
      "Data Quality Checks:\n",
      "   ✓ No null values: True\n",
      "   ✓ No empty strings: True\n",
      "   ✓ No 'unknown' values: True\n",
      "   ✓ No duplicates: True\n",
      "   ✓ Valid date formats: All dates follow Q[1-4] YYYY format\n",
      "   ✓ Valid date ranges: All end_dates are after start_dates\n",
      "\n",
      "================================================================================\n",
      "PREPROCESSING COMPLETE!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Final Data Quality Report\n",
    "print(\"\\n5. FINAL DATA QUALITY REPORT\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nDataset Statistics:\")\n",
    "print(f\"   Original rows: {initial_rows:,}\")\n",
    "print(f\"   Cleaned rows: {final_rows:,}\")\n",
    "print(f\"   Rows removed: {total_removed:,} ({(total_removed/initial_rows*100):.2f}%)\")\n",
    "\n",
    "print(f\"\\nColumn-wise Summary:\")\n",
    "for col in df_clean.columns:\n",
    "    null_count = df_clean[col].isnull().sum()\n",
    "    if df_clean[col].dtype == 'object':\n",
    "        empty_count = (df_clean[col].astype(str).str.strip() == '').sum()\n",
    "        unknown_count = df_clean[col].astype(str).str.lower().str.strip().isin(['unknown', 'nan', 'none']).sum()\n",
    "        print(f\"   {col}:\")\n",
    "        print(f\"      - Null values: {null_count}\")\n",
    "        print(f\"      - Empty strings: {empty_count}\")\n",
    "        print(f\"      - Unknown values: {unknown_count}\")\n",
    "        print(f\"      - Unique values: {df_clean[col].nunique():,}\")\n",
    "    else:\n",
    "        print(f\"   {col}:\")\n",
    "        print(f\"      - Null values: {null_count}\")\n",
    "        print(f\"      - Data type: {df_clean[col].dtype}\")\n",
    "\n",
    "print(f\"\\nData Quality Checks:\")\n",
    "print(f\"   ✓ No null values: {df_clean.isnull().sum().sum() == 0}\")\n",
    "print(f\"   ✓ No empty strings: {not (df_clean.select_dtypes(include=['object']).astype(str).apply(lambda x: x.str.strip() == '').any().any())}\")\n",
    "print(f\"   ✓ No 'unknown' values: {not (df_clean.select_dtypes(include=['object']).astype(str).apply(lambda x: x.str.lower().str.strip().isin(['unknown', 'nan', 'none'])).any().any())}\")\n",
    "print(f\"   ✓ No duplicates: {not df_clean.duplicated().any()}\")\n",
    "print(f\"   ✓ Valid date formats: All dates follow Q[1-4] YYYY format\")\n",
    "print(f\"   ✓ Valid date ranges: All end_dates are after start_dates\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PREPROCESSING COMPLETE!\")\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd78a566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "6. SAVING CLEANED DATASET\n",
      "--------------------------------------------------------------------------------\n",
      "   Cleaned dataset saved to: filter-jobs-requiring-studies-cleaned.csv\n",
      "   File size: 333,384 rows × 7 columns\n",
      "\n",
      "7. SAMPLE OF CLEANED DATA\n",
      "--------------------------------------------------------------------------------\n",
      "   person_id                              matched_label  \\\n",
      "0          0                           resource manager   \n",
      "1          0                  health and safety officer   \n",
      "2          0                       integration engineer   \n",
      "3          0                          programme manager   \n",
      "4          0    product development engineering drafter   \n",
      "5          0                               move manager   \n",
      "6          0  customer contact centre information clerk   \n",
      "7          0                      ICT help desk manager   \n",
      "8          0                        ICT help desk agent   \n",
      "9          0                    language school teacher   \n",
      "\n",
      "                                 matched_description matched_code start_date  \\\n",
      "0  Resource managers manage resources for all pot...     1324.8.3    Q1 2016   \n",
      "1  Health and safety officers execute plans for t...       2263.3    Q1 2017   \n",
      "2  Integration engineers develop and implement so...      2511.17    Q1 2013   \n",
      "3  Programme managers coordinate and oversee seve...       1213.4    Q2 2012   \n",
      "4  Product development engineering drafters desig...    3118.3.12    Q1 2011   \n",
      "5  Move managers coordinate all the resources and...       1324.4    Q1 2006   \n",
      "6  Customer contact centre information clerks pro...       4222.1    Q1 2004   \n",
      "7  ICT help desk managers monitor the delivery of...       3512.2    Q1 2002   \n",
      "8  ICT help desk agents provide technical assista...       3512.1    Q1 2000   \n",
      "9  Language school teachers educate non-age-speci...       2353.1    Q3 1996   \n",
      "\n",
      "  end_date  university_studies  \n",
      "0  Q2 2019                True  \n",
      "1  Q2 2019                True  \n",
      "2  Q1 2016                True  \n",
      "3  Q1 2013                True  \n",
      "4  Q2 2012                True  \n",
      "5  Q3 2008                True  \n",
      "6  Q4 2007                True  \n",
      "7  Q1 2004                True  \n",
      "8  Q1 2002                True  \n",
      "9  Q1 2000                True  \n"
     ]
    }
   ],
   "source": [
    "# Save cleaned dataset\n",
    "print(\"\\n6. SAVING CLEANED DATASET\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "output_filename = 'filter-jobs-requiring-studies-cleaned.csv'\n",
    "df_clean.to_csv(output_filename, index=False)\n",
    "print(f\"   Cleaned dataset saved to: {output_filename}\")\n",
    "print(f\"   File size: {len(df_clean):,} rows × {len(df_clean.columns)} columns\")\n",
    "\n",
    "# Display sample of cleaned data\n",
    "print(\"\\n7. SAMPLE OF CLEANED DATA\")\n",
    "print(\"-\" * 80)\n",
    "print(df_clean.head(10))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
